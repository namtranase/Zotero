
close this message
arXiv smileybones icon
Giving Week!

Show your support for Open Science by donating to arXiv during Giving Week, April 25th-29th.
DONATE
Skip to main content
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 30 Mar 2022]
Title: Global Tracking via Ensemble of Local Trackers
Authors: Zikun Zhou , Jianqiu Chen , Wenjie Pei , Kaige Mao , Hongpeng Wang , Zhenyu He
Download PDF

    Abstract: The crux of long-term tracking lies in the difficulty of tracking the target with discontinuous moving caused by out-of-view or occlusion. Existing long-term tracking methods follow two typical strategies. The first strategy employs a local tracker to perform smooth tracking and uses another re-detector to detect the target when the target is lost. While it can exploit the temporal context like historical appearances and locations of the target, a potential limitation of such strategy is that the local tracker tends to misidentify a nearby distractor as the target instead of activating the re-detector when the real target is out of view. The other long-term tracking strategy tracks the target in the entire image globally instead of local tracking based on the previous tracking results. Unfortunately, such global tracking strategy cannot leverage the temporal context effectively. In this work, we combine the advantages of both strategies: tracking the target in a global view while exploiting the temporal context. Specifically, we perform global tracking via ensemble of local trackers spreading the full image. The smooth moving of the target can be handled steadily by one local tracker. When the local tracker accidentally loses the target due to suddenly discontinuous moving, another local tracker close to the target is then activated and can readily take over the tracking to locate the target. While the activated local tracker performs tracking locally by leveraging the temporal context, the ensemble of local trackers renders our model the global view for tracking. Extensive experiments on six datasets demonstrate that our method performs favorably against state-of-the-art algorithms. 

Comments: 	10 pages; 6 figures; accepted to CVPR2022
Subjects: 	Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2203.16092 [cs.CV]
  	(or arXiv:2203.16092v1 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2203.16092
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Zikun Zhou [ view email ]
[v1] Wed, 30 Mar 2022 06:44:47 UTC (2,106 KB)
Full-text links:
Download:

    PDF
    Other formats 

Current browse context:
cs.CV
< prev   |   next >
new | recent | 2203
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export bibtex citation Loading...
Bookmark
BibSonomy logo Mendeley logo Reddit logo ScienceWISE logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code & Data
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

