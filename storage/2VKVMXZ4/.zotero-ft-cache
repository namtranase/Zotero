Local Metrics for Multi-Object Tracking
Jack Valmadre, Alex Bewley, Jonathan Huang, Chen Sun, Cristian Sminchisescu, Cordelia Schmid Google Research

arXiv:2104.02631v1 [cs.CV] 6 Apr 2021

Abstract
This paper introduces temporally local metrics for MultiObject Tracking. These metrics are obtained by restricting existing metrics based on track matching to a ﬁnite temporal horizon, and provide new insight into the ability of trackers to maintain identity over time. Moreover, the horizon parameter offers a novel, meaningful mechanism by which to deﬁne the relative importance of detection and association, a common dilemma in applications where imperfect association is tolerable. It is shown that the historical Average Tracking Accuracy (ATA) metric exhibits superior sensitivity to association, enabling its proposed local variant, ALTA, to capture a wide range of characteristics. In particular, ALTA is better equipped to identify advances in association independent of detection. The paper further presents an error decomposition for ATA that reveals the impact of four distinct error types and is equally applicable to ALTA. The diagnostic capabilities of ALTA are demonstrated on the MOT 2017 and Waymo Open Dataset benchmarks.
1. Introduction
Multi-Object Tracking (MOT) algorithms aim to predict a set of tracks corresponding to the unique instances of a given class in a video. Trackers must be evaluated for their ability to both detect and associate objects.1 While detection errors can be measured by simply counting false positives and false negatives in each frame, there are multiple possible ways to treat association errors during evaluation. Moreover, the signiﬁcance of association errors depends on the application. For example, in surveillance applications, an association error represents a critical failure, whereas for action recognition or trajectory forecasting, it may be sufﬁcient for tracks to be only locally correct.
Existing MOT metrics can thus be divided into two distinct categories: strict metrics, which require the association to be correct for the entire sequence, and non-strict metrics, which seek to award partial credit for tracks that are only correct within a subset of frames. Strict metrics
1Even if two trackers start from an identical per-frame detector, their detection characteristics will depend on their use of temporal information.

✓

✗

✓

✓

✗

Figure 1. The proposed local metrics establish one-to-one correspondence between tracks within a ﬁnite horizon r of each frame t. Thin black lines represent ground-truth tracks while coloured lines denote distinct predicted tracks.

establish one-to-one correspondence between entire tracks, whereas non-strict metrics typically adopt a time-varying correspondence and use a soft association metric to quantify the confusion between tracks. Examples of strict metrics are Identiﬁcation F1-score (IDF1) [54] and Average Tracking Accuracy (ATA) [45], while examples of non-strict metrics are Multi-Object Tracking Accuracy (MOTA) [4] and Higher Order Tracking Accuracy (HOTA) [43].
While the application governs which type of metric is suitable, each has associated drawbacks. For non-strict metrics, it is unclear how best to deﬁne a scalar measure of association quality, leading to a proliferation of non-strict metrics [60, 4, 27, 36, 43, 18]. Moreover, when combined with a detection metric, each association metric induces an implicit trade-off between detection and association which may not be well understood. Strict metrics, on the other hand, generally lack error-type differentiability [36] as a result of their monolithic track comparison. Furthermore, there is a distinct absence of temporal information in metrics of either type. In fact, with the exception of identity switches in MOTA [4], existing metrics are invariant to permutation of the frames, effectively evaluating the association of detections into tracks as a clustering problem. This paper seeks to address these deﬁciencies through several contributions.
Contribution 1. We introduce local metrics that generalise the existing strict metrics IDF1 and ATA. The local metrics, designated LIDF1 and ALTA, are parametrised by a temporal horizon and thereby reveal the temporal ranges at which association errors occur, see Figure 1. Fur-

thermore, the local metrics themselves constitute non-strict metrics which circumvent the need to choose a soft measure of track confusion and which possess an explicit, meaningful mechanism to set the balance between association and detection. The horizon(s) of interest depend on the application. Empirically, we verify that the local metrics capture a wide range of trade-offs compared to existing metrics and show that ATA better represents association errors than IDF1.
Contribution 2. We demonstrate that error-type differentiability can be achieved in ATA using independent perframe correspondence. The overall tracking error in ATA is approximately decomposed into four distinct error types. This is valuable both to developers and users of tracking algorithms, who need to understand how algorithms differ with respect to error modes. The error decomposition applies equally well to the local metrics, revealing the shifting distribution of error types as the horizon is varied.
Contribution 3. We use ALTA to re-evaluate the predictions of state-of-the-art trackers on the MOT 2017 and Waymo Open Dataset benchmarks. Analysis of the metric at different horizons clearly shows that trackers which account for longer-term dependencies such as MAT [20] and Lif T [24] are better able to maintain identity over time. Conversely, trackers which can only capture short-term dependencies such as TubeTK [48] experience a rapid drop in accuracy as the horizon increases, despite achieving excellent detection accuracy.
2. Existing metrics and related work
Strict metrics establish one-to-one correspondence between ground-truth and predicted tracks, usually to maximise a measure of track overlap. The two key strict metrics in the literature are IDF1 [54] and ATA [45]. The main difference is that IDF1 measures overlap by the number of frames in which two tracks overlap, whereas ATA uses spatiotemporal IOU (Intersection Over Union). That is, IDF1 gives equal weight to each detection and ATA gives equal weight to each track. These metrics will be described in greater detail in the next section. One noted weakness of IDF1 is its invariance to the association of unmatched tracks [43, 18]. While ATA seems to have been abandoned due to its inability to provide a separate measure of localisation error [62], we will consider it as a viable alternative.
Strict metrics have also been proposed for problems like video object detection, where a class must be predicted for each track. Here, it is standard to use a binary criterion for track overlap and obtain per-class precision-recall curves using conﬁdence scores [42, 26, 16]. This approach focuses on detection rather than diagnosing tracking errors.
Non-strict metrics generally permit the correspondence between ground-truth and predicted tracks to vary over time and adopt some measure of confusion between tracks. Since

it is difﬁcult to optimise for a time-varying correspondence, most approaches either use independent, per-frame correspondence or an approximate algorithm.
The most prevalent metric in recent history is MOTA [4], which quantiﬁes association error using the number of identity switches. These are added to detection errors to obtain
MOTA = 1 − (DetFN + DetFP + IDSw)/N (1)
where N is the number of ground-truth boxes. Amongst various issues with MOTA [43], the most critical is that detection errors overwhelm identity switches, rendering it almost a pure detection metric [19, 44, 25, 43]. Weng et al. [70] consider the integral of MOTA with respect to recall by varying a per-box conﬁdence threshold, however this remains primarily a measure of detection. While improvement in detection can serve as a proxy for tracker performance [17], it ignores the quality of the tracks.
Several historical works have proposed alternative ways to quantify association error in a non-strict manner. Smith et al. [60] measured the average fraction of each groundtruth and predicted track covered by its best match, achieving partial credit by not enforcing one-to-one correspondence. Kao et al. [27] quantiﬁed confusion using conditional entropy, similar to the V -measure in clustering [55]. Leichter and Krupka [36] instead measured confusion between tracks using the fraction of frame pairs in each track with the same correspondence, similar to the Rand index in clustering [52]. More recently, Feng et al. [18] quantiﬁed track confusion using the two-norm of overlap between all tracks. The diversity of proposals illustrates the inherent subjectivity of quantifying association in MOT.
Luiten et al. [43] recently proposed HOTA, which measures association accuracy using the average fraction of frames in the same track with the same association. This is similar to the pair-based metric of Leichter and Krupka except that HOTA adopts a deﬁnition of association accuracy that includes false-positive and false-negative detections to ensure that adding a true-positive detection increases the tracking metric regardless of its association. The overall HOTA metric is obtained as the geometric mean of detection and association accuracy, averaged over multiple thresholds for spatial overlap. Since it is computationally infeasible to ﬁnd a time-varying correspondence which exactly maximises HOTA, a near-optimal correspondence is instead sought by maximising a surrogate objective.
Leichter and Krupka [36] argued that metrics should possess error-type differentiability and enumerated the different error types in MOT. Besides inaccurate localisation, these are characterised as under-detection (false negative), over-detection (false positive), under-association (split) and over-association (merge). The two association errors are illustrated in Figure 2. The same authors proposed that metrics should be monotonic, meaning that eliminating one er-

Split
Merge
Figure 2. Association errors can be divided into two types. Split errors occur when one ground-truth track is associated to two predicted tracks (top) and, conversely, merge errors occur when one predicted track is associated to two ground-truth tracks (bottom).

ror without introducing another does not degrade the metric. Unfortunately, this places no constraint on the metric’s behaviour when a missed detection is corrected but the new detection is incorrectly associated.
Finally, Kim et al. [32] recently introduced a metric for panoptic video segmentation that evaluates tracks in a sliding window, similar to our proposed approach. Since their primary focus is segmentation accuracy, they do not consider the role of association errors and restrict their analysis to a maximum window of 15 frames.

3. Local metrics

This section deﬁnes IDF1 and ATA in a common framework and develops the extension of each to ﬁnite horizons.

3.1. Preliminaries

Consider a video with T frames and K ground-truth
tracks. Let t ∈ [T ] {1, . . . , T } denote the frames and
i ∈ [K] denote the ground-truth tracks. For each ground-
truth track i, let Vi ⊆ [T ] denote the subset of frames in which it is visible and let the rectangle yi(t) be its position in the image at each time t ∈ Vi. Similarly, let Kˆ denote the number of predicted tracks, Vˆj ⊆ [T ] denote the subset of frames in which predicted track j ∈ [Kˆ ] is visible and yˆj(t) be its position at time t ∈ Vˆj.
For each frame t, let B(t) denote a K ×Kˆ binary overlap
matrix indicating the overlap of each ground-truth track i
and predicted track j

Bij(t) =

1, 0

t ∈ Vi ∩ Vˆj ∧ IOU(yi(t), yˆj(t)) ≥ 0.5 otherwise.

The sequence of binary matrices B(t) represents sufﬁcient information to compute IDF1 and ATA. The use of a perframe, binary overlap criterion facilitates the study of detection and association errors as discrete events and ensures that the tracking metric is not affected by imprecise localisation. If sensitivity to localisation is desired, the metric can be averaged over multiple thresholds, e.g. [43].
3.2. Identiﬁcation F1-score
IDF1 [54] establishes correspondence between entire tracks to maximise the total number of frames in which

corresponding tracks overlap, referred to as the Identiﬁca-

tion True Positives (IDTP). In our formulation, the number

of frames in which each ground-truth track i and predicted

track j overlap can be obtained by taking the sum of binary

overlap matrices B =

T t=1

B(t).

Let us represent the set of one-to-one matchings between

the two sets of tracks by the binary matrices

M = A ∈ {0, 1}K×Kˆ | A1 ≤ 1, AT 1 ≤ 1 (2)

where the element of Aij indicates the selection of edge (i, j) in the bipartite graph. The maximum number of overlapping frames between matched tracks is then obtained by solving the linear assignment problem

IDTP = max A, B

(3)

A∈M

where A, B = tr(AT B) = i,j AijBij. The F1-score is deﬁned in terms of the recall and precision of this subset

IDF1

=

M−1(IDR,

IDP)

=

IDTP/[

1 2

(N

+

Nˆ )]

(4)

where N = i |Vi| and Nˆ = j |Vˆj| denote the total number of boxes in the ground-truth and predicted tracks,
the recall and precision are deﬁned IDR = IDTP/N and IDP = IDTP/Nˆ and Mp is the p-mean.

3.3. Local Identiﬁcation F1-score

To generalise IDF1 to a local metric, we instead consider the identiﬁcation true positives within a temporal interval [a, b] {t ∈ [T ] : a ≤ t ≤ b}

IDTP[a,b] = max A,
A∈M

t∈[a,b] B(t) .

(5)

Importantly, each interval can adopt different correspondence between the two sets. The terms N and Nˆ can,
likewise, be written as the sum of an indicator function
1X (x) = 1[x ∈ X ] and restricted to the interval [a, b]

N[a,b] = t∈[a,b] i 1Vi (t) .

(6)

To obtain a local metric with temporal horizon r ≥ 0, we take the mean of these quantities over all intervals [t − r, t + r] for t ∈ [T ]

LIDF1(r) =
1 2T

1 T

T t=1

IDTP[t−r,t+r]

T t=1

N[t−r,t+r] + Nˆ[t−r,t+r]

.

(7)

The mean numerator and denominator are used rather than the mean fraction to gracefully handle empty intervals. The same approach of accumulating numerators and denominators is used to obtain the metrics for multiple sequences, where the factor 1/T is important if there are sequences of different length.

3.4. Average Tracking Accuracy

ATA [45] is similar to IDF1, establishing per-video correspondence between entire tracks. The key difference is that ATA measures the fraction of correct tracks.
Let Q denote the temporal IOU matrix whose elements are the number of frames in which two tracks overlap divided by the number of frames in which either is present

Qij = Bij /|Vi ∪ Vˆj | .

(8)

The average track accuracy is then deﬁned

ATA

=

TrackTP/[

1 2

(K

+

Kˆ )]

(9)

where TrackTP = maxA∈M A, Q is the maximum sum of track overlap in a one-to-one correspondence between
the two sets of tracks. Similarly to IDF1, the metric can
be understood as the harmonic mean of recall ATR = TrackTP/K and precision ATP = TrackTP/Kˆ .

3.5. Average Local Tracking Accuracy

The local metric is similarly obtained by restricting the numerator and denominator to intervals with horizon r and taking the mean over intervals

ALTA(r) =
1 2T

1 T

T t=1

TrackTP[t−r,t+r]

T t=1

K[t−r,t+r] + Kˆ [t−r,t+r]

.

(10)

The interval-restricted numerator is obtained by ﬁnding the optimal correspondence between tracks within the interval

TrackTP[a,b] = max A, Q[a,b]

(11)

A∈M

where Q[a,b] is the temporal IOU matrix with elements

Q[a,b] ij =

t∈[a,b] Bij (t) . t∈[a,b] 1Vi∪Vˆj (t)

(12)

The denominator terms K[a,b] and Kˆ[a,b] are found by counting the number of tracks present within the interval.

3.6. Properties of local metrics

It is straightforward to verify that, for r ≥ T − 1, each local metric reduces to its strict counterpart, LIDF1(r) = IDF1 and ALTA(r) = ATA. Conversely, for r < 1 (singleframe windows), both reduce to the detection F1-score

LIDF1(r) = ALTA(r) = DetF1

1 T

DetTP

1 2T

(N

+

Nˆ )

.

(13)

The detection metric is an upper bound of the local metrics DetF1 ≥ IDF1(r), ALTA(r) since it can choose the optimal correspondence independently for each frame. This

Association (IDF1 / DetF1)

1.0

IDF1 - Factorization - MOT17 test

0.726 (1) * CSTrack

0.723 (2) * Fair

0.692 (3) MAT

0.8

0.687 (4) * GSDT 0.680 (5) * FUFET

0.656 (6) Lif_T

0.652 (7) Lif_TsimInt

0.6

0.647 (8) * CTTrack17

0.639 (9) * TraDeS

0.631 (10) TT17

0.4

0.631 (11) * MAT2 0.623 (12) LSST17

0.617 (13) MPNTrack

0.596 (14) CTTrackPub

0.2

0.595 (15) HDTR

0.581 (17) eTC17

0.581 (18) UnsupTrack

0.00.0

0.2

0.4

0.6

0.8

0.572 (22) SAS_MOT17 1.0

Detection (DetF1)

Association (ATA / DetF1)

1.0

ATA - Factorization - MOT17 test

0.443 (1) MAT

0.382 (2) Lif_TsimInt

0.381 (3) Lif_T

0.8

0.379 (4) * GSDT 0.379 (5) MPNTrack

0.376 (6) TT17

0.6

0.371 (7) * Fair 0.369 (8) LSST17

0.356 (9) * CSTrack

0.322 (10) * CTTrack17

0.4

0.321 (11) GSM_Tracktor 0.318 (12) HDTR

0.316 (13) * FUFET

0.315 (14) TPM

0.2

0.314 (15) eHAF17

0.310 (17) UnsupTrack

0.309 (18) * MAT2

0.00.0

0.2

0.4

0.6

0.8

0.296 (22) CTTrackPub 1.0

Detection (DetF1)

Figure 3. Factorisation of IDF1 and ATA into detection and association for the 70 published submissions to the MOT 2017 Challenge. The implicit association metric of ATA has a much greater effect on the overall score, hence the use of a private detector (solid marker) provides a greater advantage under IDF1. The Pareto front is shown separately for all methods and for those that use public detections. The legend lists the union of top ten trackers and top ﬁve per dimension. The curves depict level sets of the metric.

means that comparing the local tracking metric to the detection metric reveals the impact of association errors.
Computing the local metrics requires solving O(T ) bipartite matching problems per horizon. Assuming that Kˆ is O(K), each can be solved in O(K3) by the Hungarian algorithm [33] and the cost matrix of each problem can be constructed in O(K2) time using summed area tables, which themselves are obtained in O(T K2) time total. Therefore, evaluating the local metric for H different horizons requires O(HT K3) time, roughly H times as expensive as MOTA and HOTA, which also solve an assignment problem per frame. One advantage of the local metrics is that they use the optimal correspondence, whereas MOTA and HOTA depend on approximations. Furthermore, there may exist a more efﬁcient algorithm (like Toroslu and U¨ c¸oluk [65]) which re-use effort from interval t to solve interval t + 1, seeing as the edge weights change gradually.

Kendall rank correlation
Correlation with IDSw/DetTP

1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 MOTA

HOTA HOTA0.5

DetF1 IDSw/DetTP
IDF1 ATA

vs ALTA(x) vs ALTA(x)

vs LIDF1(x) vs LIDF1(x)

1

10

100 1000

Horizon (frames)

1.0

MOTA

HOTA

IDF1

0.8

LIDF1

ATA

ALTA

0.6

0.4

0.4

0.6

0.8

1.0

Correlation with DetF1

Figure 4. Left: Rank correlation of tracking metrics with detection F1-score and normalised identity switches based on the 125 submissions to the MOT 2017 Challenge [46]. ATA is more correlated with association and less correlated with detection than IDF1, HOTA and MOTA. The black dotted line illustrates the “baseline” correlation between detection F1-score and identity switches. Middle: Our local versions of IDF1 and ATA trace a spectrum between pure detection towards the strict tracking metrics as the temporal horizon increases. Right: The local metrics trace a path in the detection-association spectrum while other metrics correspond to a particular trade-off.

4. Comparative study of metrics
This section studies the relative impact of detection and association on existing metrics and the proposed local metrics. It will be established that, for trackers submitted to the MOT 2017 Challenge, association plays a more signiﬁcant role in ATA than in IDF1. The range of trade-offs captured by the local metrics will further be characterised relative to existing non-strict metrics.
As described in the previous section, the impact of association on ATA and IDF1 can be measured by considering each as a fraction of DetF1, corresponding to single-frame windows. Figure 3 presents the factorisation of IDF1 and ATA into DetF1 and this association fraction for submissions to the MOT 2017 Challenge [46]. Association has a greater impact on ATA than on IDF1, since the tracking metric is a smaller fraction of the detection metric. Notably, four of the top ﬁve trackers under IDF1 make use of an external detector, whereas this statistic is reversed under ATA.
To characterise the degree to which different overall metrics capture detection and association, we compare the ranking that each metric induces on the submissions to the MOT 2017 Challenge [46]. Speciﬁcally, in Figure 4, we measure the Kendall rank correlation of each metric with (i) the detection F1-score and (ii) the rate of identity switches per correct detection2. It is immediately apparent that ATA exhibits the strongest correlation with identity switches and the least with detection. Conversely, MOTA is highly correlated with detection and barely represents identity switches better than the detection metric itself (the dotted line). While IDF1 and ATA are both strict metrics, IDF1 exhibits greater dependence on detection. HOTA is somewhat less
2We do not argue that the number of identity switches is the best way to quantify association error, we simply adopt it as an established reference. We normalise by the number of true-positive detections since trackers that detect more objects have greater potential for identity switches.

strict than IDF1 with respect to association, and the integral over localisation thresholds has little effect on these particular correlation measures. The center and right plots of Figure 4 mark the range of metrics that are attained by varying the horizon in our local variants. ALTA achieves a greater range of characteristics than LIDF1.
Given that (i) we are most interested in track accuracy and (ii) ALTA can express a greater range of trade-offs, we will concentrate on ALTA for the remainder of the paper. LIDF1 may still be preferred for applications where short, incorrect tracks are of minor importance.

5. Error type decomposition

To determine a tracker’s suitability for an application,

it is crucial to have transparency with respect to different

error types. Here we develop a decomposition of ATA (and

by extension ALTA) error into the two types of detection

error (false positive and false negative) and the two types of

association error (split and merge), see Figure 2).

The fundamental idea behind the decomposition is to use

a per-frame correspondence to categorise the different er-

rors that occur within each track. Let C(t) ∈ M denote

the independent, per-frame correspondence which is used

to measure detection error. We can obtain a good approxi-

mation to ATA by replacing the number of frames in which

two tracks overlap, B, with the number in which they are

matched in the per-frame correspondence, C =

T t=1

C (t),

TrackTP = max A, Q ,
A∈M

Qij

=

Cij |Vi ∪ Vˆj|

.

(14)

This ensures per-frame exclusivity and is a good approximation since the majority of detections have only a single candidate with IOU ≥ 0.5.
We now present the error decomposition for track recall using this approximation. For track precision, error types

are simply exchanged. Let π(i) denote the corresponding predicted track for each ground-truth track i in the optimal matching A from eq. 14. We rewrite the recall as the mean temporal IOU of ground-truth track i with its partner π(i)

1K

ATR = K

Qi,π(i) ,

i=1

Qi,π(i)

=

Ci,π(i) |Vi ∪ Vˆπ(i)|

(15)

If track i is unmatched, we set Vˆπ(i) = ∅ and Ci,π(i) = 0. The recall error is then equal to the mean per-track error,

1

−

ATR

=

1 K

K i=1

1 − Qi,π(i)

.

(16)

To decompose the error for track i, we consider the fraction

of each track which is covered by its assigned partner, by its

best possible partner, and by any other track. These deﬁne

a series of upper bounds on Qi,π(i) =

Ci,π(i) |Vi ∪ Vˆπ(i)|

≤

Ci,π(i) |Vi|

≤

maxj Cij |Vi|

≤

j Cij ≤ 1 . |Vi|

ρπi

ρbiest

ρdiet

The gaps between these inequalities provide a decomposition 1 − Qi,π(i) = (1 − ρdiet) + (ρdiet − ρbiest) + (ρbiest − ρπi ) + (ρπi − Qi,π(i)) where each term is caused by a speciﬁc error type. Speciﬁcally, within ground-truth track i,

1. (1 − ρdiet) represents frames that were not matched to any predicted track, i.e. false-negative detection errors,

2. (ρdiet − ρbiest) represents frames which were matched to some track other than the best possible partner, which only occurs if the ground-truth track i was matched to multiple predicted tracks, i.e. split errors, and

3. (ρbiest − ρπi ) is the difference between the best possible partner and the actual assigned partner, which only ex-
ists if the best partner was matched to multiple groundtruth tracks, i.e. merge errors.

The remaining gap, due to the union denominator, is

ρπi − Qi,π(i) =

1 − |Vi|
|Vi ∪Vˆπ(i) |

Ci,π(i) |Vi |

(17)

and represents the frames Vˆπ(i) \ Vi in which the matching predicted track π(i) is present but track i itself is not.

These frames of the predicted track can be partitioned into

those which are not associated with any ground-truth track

(i.e. false-positive detection errors) and those which are as-

sociated to a different ground-truth track (i.e. track merge

errors), thus completing the decomposition. To obtain a de-

composition of the overall error, we note

1

−

ATA

=

1 K +Kˆ

[K

(1

−

ATR)

+

Kˆ (1

−

ATP)]

=

1 K+Kˆ

[

i(1 − Qi,π(i)) +

j (1 − Qπ−1(j),j )] (18)

and then use the approximate decompositions of each error.

Figure 6 illustrates the decomposition of recall and pre-

cision for several trackers from the MOT 2017 Challenge.

ALTA - Temporal behaviour - MOT17 test
0.9

ALTA(x)

0.8

MAT

0.7

Lif_T MPNTrack

* Fair

0.6

LSST17

* CTTrack17

0.5

DMAN CTTrackPub

Tracktor++v2

0.4

* Tube_TK

LSST17O

0.3

0.2 1

10

100

1000

Horizon (frames)

Figure 5. ALTA versus the horizon parameter for high-performing trackers on the MOT 2017 Challenge test set. The * denotes trackers that use detections other than provided by the benchmark.

6. Tracker analysis with ALTA
To demonstrate the utility of ALTA and its error decomposition we compare a diverse set of state-of-the-art trackers from the MOT 2017 Challenge [46] and Waymo Open Dataset [63] tracking benchmark. Metrics for the private test sets were obtained by providing code to the dataset maintainers. Extended results can be found in the appendix.
6.1. MOT 2017 Challenge
We brieﬂy describe the trackers considered. Tracktor++v2 [3] uses the second stage of Faster R-CNN [53] to ﬁnd the new location of each track, compensating for camera motion and performing re-ID with a Siamese network, subject to a strict overlap criterion. LSST17 [19] combines a single-object tracker [37], a deep re-ID embedding and a tree-based, “switcher-aware” classiﬁer. The default variant uses agglomerative clustering to construct tracks and the online variant, LSST17O, does not. DMAN [86] extends a single-object tracker [15] using a Siamese network and a bi-directional LSTM to compare detections to tracklets. CTTrack17 is CenterTrack [85], which performs auto-regressive offset regression, taking the previous image and prediction as input. CTTrackPub is a variant constrained to only start tracks using the standard, public detections. Fair [83] is an anchor-free CNN detector that is jointly trained to predict instance embeddings. TubeTK [48] uses a CNN to predict tubes as temporal splines and then links these tubes using their overlap and velocity. MPNTrack [8] trains a Message Passing Network to operate on the graph of detections and predict the validity of putative edges. Lif T [24] adds long-term cues to existing paths in a network ﬂow formulation with simple motion-based features, with Tracktor-style interpolation [3] as post-processing. MAT [20] (Motion Aware Tracker) is

Table 1. Evaluation of representative trackers in the MOT 2017 Challenge using key existing metrics and ALTA at horizons of one and ﬁve seconds. Asterisks * denote the use of a detector besides that provided by the benchmark. The rank within each metric is indicated in parentheses with the top ﬁve in bold. The mean of three horizons is adopted as an illustrative example of a general purpose metric.

Tracker

DetF1 MOTA HOTA HOTA0.5 IDF1 ALTA(1s) ALTA(5s) ATA

↑ mean

MAT [20] * Fair [83] MPNTrack [8] Lif T [24] LSST17 [19] * CTTrack17 [84] CTTrackPub [84] DMAN [86] Tracktor++v2 [3] * Tube TK [48] LSST17O [19]

.769 (2) .818 (1) .704 (7) .710 (5) .681 (8) .763 (3) .709 (6) .631 (11) .673 (9) .753 (4) .662 (10)

.671 (3) .737 (1) .588 (7) .605 (6) .547 (9) .678 (2) .615 (5) .482 (11) .563 (8) .630 (4) .527 (10)

.560 (2) .593 (1) .490 (5) .513 (4) .471 (8) .522 (3) .482 (6) .425 (11) .448 (9) .480 (7) .443 (10)

.677 (2) .719 (1) .603 (5) .638 (4) .589 (7) .651 (3) .595 (6) .532 (11) .550 (10) .586 (8) .554 (9)

.692 (2) .723 (1) .617 (6) .656 (3) .623 (5) .647 (4) .596 (7) .557 (10) .551 (11) .586 (8) .579 (9)

.660 (1) .623 (2) .596 (3) .585 (4) .565 (6) .583 (5) .552 (7) .506 (10) .525 (9) .529 (8) .479 (11)

.520 (1) .455 (3) .456 (2) .451 (4) .447 (5) .406 (6) .385 (7) .378 (8) .351 (9) .312 (11) .315 (10)

.443 (1) .371 (4) .379 (3) .381 (2) .369 (5) .322 (6) .296 (8) .312 (7) .283 (9) .247 (10) .245 (11)

.541 (1) .483 (2) .477 (3) .473 (4) .461 (5) .437 (6) .411 (7) .399 (8) .386 (9) .363 (10) .346 (11)

an enhanced SORT [5], accounting for camera motion and permitting re-association at greater temporal distances.
Figure 5 shows ALTA as a function of horizon. As the horizon increases, the ordering of the trackers undergoes signiﬁcant change, as some are much better at associating tracks over greater temporal distances. Most of the trackers with the best detection accuracy experience a severe drop in ALTA as the horizon increases, especially CTTrack17 and TubeTK, which lack a mechanism to perform longer-term association. This suggests that powerful detectors have effectively compensated for poor association in the past, whereas ATA makes this more difﬁcult. One exception to this trend is MAT [20], which has good detection accuracy while still associating tracks robustly over longer time-scales by extrapolating tracks with a Kalman ﬁlter and camera motion compensation. MAT uses the public set of detections and, surprisingly, does not use appearance features in re-association. On the other hand, some trackers with only reasonable detection accuracy are particularly effective at maintaining association over time, in particular MPNTrack, LSST17 and Lif T. These trackers all incorporate longer-term cues for association. DMAN also achieves reasonable ATA despite starting with particularly poor detection accuracy. Comparing LSST17 to its online variant LSST17O, which does not use agglomerative clustering, reveals a marked difference in association quality over time.
Table 1 compares DetF1, MOTA, HOTA and IDF1 to ATA and ALTA at one and ﬁve second horizons. While we do not claim to propose a universal scalar metric, since no single metric will be suitable for all applications, we order trackers in this table by the mean ALTA at three horizons as an illustrative example of a general purpose metric. One advantage of a mean ALTA metric is that the contribution of each time-scale is known. The trackers which best maintain associations over longer time intervals, MAT, MPNTrack, and Lif T, are ranked higher under ATA than other metrics. The methods which depend on detection, Fair, CTTrack17 and Tube TK, drop in the ranking under ALTA.
Figure 6 depicts the error decomposition of precision

Track Prec

1.0

0.8

0.6

0.4

0.2

0.0

Tr*aCcCT*kLTTtTrSTourarSDcab*T+kceM1F_kP+7AaTv1uiNOrK27b MPLNSTSLriTfa1_cT7k MAT

* MFAaiTr

Precision error (predicted tracks) FP det Merge (contains multiple) Split (best match unavailable) Split (in partner, not in track) FN det (in partner, not in track) Recall error (ground-truth tracks) FN det Split (contains multiple) Merge (best match unavailable) Merge (in partner, not in track) FP det (in partner, not in track)

* TubLei_fT_TK Tr*aCcCTMkLTTtPSTroLaNSrrSDac+TTSMkc1r+TPkaA711uvcON727bk0.0

0.2

0.4

0.6

0.8

1.0

Track Recall

Figure 6. ATA is computed as the harmonic mean (top right) of track precision and track recall. The bar graphs show the decomposition of precision error (top left) and recall error (bottom right).

and recall. This reveals that, for these trackers, recall is dominated by false-negative detections, while precision is most affected by split errors. Split errors affect the precision both in that (a) the best match for a predicted track is often unavailable in a one-to-one correspondence and (b) the ground-truth track with which a predicted track is matched often contains frames where the predicted track is not present. This is indicative of over-segmentation of the ground-truth track into multiple predictions. Examining individual trackers, we ﬁrst observe that Fair achieves excellent recall by reducing false-negative detections, however its precision suffers from a signiﬁcant fraction of falsepositive detections. While Tube TK and CTTrack17 also

ATA MAT MPNTLrifa_cTk * CTTLrSa*ScTFk1a1i7r7 TraCcT*kLTtTrSouarSDcbT+keM1_P+7ATvuNOK2b
ALTA(x)

1.0

MOT17 test

0.8

0.6

0.4

0.2

0.0

Det false neg Det false pos Assoc split Assoc merge Correct (approx)

Figure 7. The relative impact of each error type on ATA per tracker.

1.0

MOT17 test - Tracktor++v2

1.0

MOT17 test - LSST17

0.8

0.8

0.6

0.6

0.4

Error: det, false neg

0.4

Error: det, false neg

Error: det, false pos

Error: det, false pos

Error: assoc, split

Error: assoc, split

0.2

Error: assoc, merge

0.2

Error: assoc, merge

ALTA (approx)

ALTA (approx)

ALTA

ALTA

0.0 100

101

102

103

0.0 100

101

102

103

Horizon (frames)

Horizon (frames)

Figure 8. Relative impact of each error type at different temporal

horizons. The approximate ALTA is close to the true value.

reduce the rate of false-negative detections using an external detector, their recall is signiﬁcantly affected by association errors. The trackers with the best track precision are MAT, LSST17 and MPNTrack, while only MAT achieves this at a high recall. Despite having the least false-positive detections, the precision of Tracktor++v2 is limited by its high prevalence of split errors.
Figure 7 shows the relative contribution of each error type to the overall score. This reveals that split errors account for a much larger component than merge errors and that the trackers with the highest ATA generally have the smallest association error component. LSST17 in particular achieves an impressive ATA score given the large contribution of false-negative detection errors. Note that eq. 18 gives equal weight to predicted and ground-truth tracks, therefore the relative importance of precision and recall in the overall decomposition depends on the number of predicted tracks.
Figure 8 visualises the varying distribution of error types with respect to horizon. As the horizon approaches zero, the association errors disappear. As the horizon increases, so does the fraction of association errors, which is dominated by split errors for both trackers.
6.2. Waymo Open Dataset
We also evaluate submissions to the Waymo Open Dataset [63] for vehicle tracking, comprising 20 sec sequences at 10Hz. Autonomous driving further motivates the

ALTA - Waymo test (vehicle)

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0.0

1

10

100

Horizon (frames)

Quasi-Dense R101 CascadeRCNN-SORT v2 dereyly_alex HorizonMOT FCTrack DSTNet Sort ATSS-Track Online V-IOU

Figure 9. ALTA versus horizon for submissions to the Waymo Open Dataset 2D Tracking competition. † indicates trackers with either missing publication or not submitted by an original author.

temporal horizon, as its requirements differ greatly from applications such as surveillance or object counting. Speciﬁcally, knowing the path of a car in the previous seconds is more informative for trajectory prediction than the ability to recognise a car from several minutes ago. Different types of association error also incur different costs: split errors may mean the re-initialisation of a motion model while merge errors may result in unreliable velocity estimates.
Figure 9 plots ALTA at different horizons for a subset of trackers listed on the public benchmark. Two interesting trackers to compare are Quasi-Dense R101 and Online VIOU. While both have high detection accuracy, the latter shows a steeper drop in association over just one second (ten frames). Extended results are found in the appendix.
7. Conclusion
This paper has highlighted the dilemma posed by association in non-strict metrics for MOT. The proposed local metrics provide an intuitive and meaningful way for benchmarks to specify the desired balance between detection and association, as well as providing insight into the temporal distribution of association errors. Compared to current popular metrics, ATA and ALTA are able to place greater importance on association, diminishing the advantage of using an external detector. Coupling the horizon parameter with error-type transparency makes ALTA a powerful tool for both quantifying and understanding tracker accuracy. We have demonstrated its expressivity using the MOT 2017 and Waymo Open Dataset benchmarks and believe ALTA is a valuable metric for MOT researchers and practitioners alike. Furthermore, the adoption of a ﬁnite maximum horizon may simplify video annotation and help protect individual privacy by distinguishing tracking from re-identiﬁcation. Code will be made available online.

Acknowledgements We extend an enormous thanks to Patrick Dendorfer (MOT Challenge) and Pei Sun (Waymo Open Dataset) for running our code on the private test set. We also thank Jonathan Luiten, Vivek Rathod and Zhichao Lu for valuable discussions and feedback.
References
[1] Maryam Babaee, Ali Athar, and Gerhard Rigoll. Multiple people tracking using hierarchical deep tracklet reidentiﬁcation. arXiv preprint arXiv:1811.04091, 2018.
[2] Nathanael L Baisa. Occlusion-robust online multi-object visual tracking using a GM-PHD ﬁlter with a CNN-based reidentiﬁcation. arXiv preprint arXiv:1912.05949, 2019.
[3] Philipp Bergmann, Tim Meinhardt, and Laura Leal-Taixe. Tracking without bells and whistles. In Proceedings of the IEEE International Conference on Computer Vision, pages 941–951, 2019.
[4] Keni Bernardin and Rainer Stiefelhagen. Evaluating multiple object tracking performance: The CLEAR MOT metrics. EURASIP Journal on Image and Video Processing, 2008, 2008.
[5] Alex Bewley, Zongyuan Ge, Lionel Ott, Fabio Ramos, and Ben Upcroft. Simple online and realtime tracking. In 2016 IEEE International Conference on Image Processing (ICIP), pages 3464–3468. IEEE, 2016.
[6] Erik Bochinski, Volker Eiselein, and Thomas Sikora. Highspeed tracking-by-detection without using image information. In 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), pages 1–6. IEEE, 2017.
[7] Erik Bochinski, Tobias Senst, and Thomas Sikora. Extending IOU based multi-object tracking by visual information. In 2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS). IEEE, 2018.
[8] Guillem Braso´ and Laura Leal-Taixe´. Learning a neural solver for multiple object tracking. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6247–6257, 2020.
[9] Zhaowei Cai and Nuno Vasconcelos. Cascade R-CNN: High quality object detection and instance segmentation. IEEE Trans. Pattern Anal. Mach. Intell., 2019.
[10] Jiahui Chen, Hao Sheng, Yang Zhang, and Zhang Xiong. Enhancing detection model for multiple hypothesis tracking. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 18–27, 2017.
[11] Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li, Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, et al. MMDetection: Open MMLab detection toolbox and benchmark. arXiv preprint arXiv:1906.07155, 2019.
[12] Long Chen, Haizhou Ai, Rui Chen, and Zijie Zhuang. Aggregate tracklet appearance features for multi-object tracking. IEEE Signal Processing Letters, 26(11):1613–1617, 2019.
[13] Long Chen, Haizhou Ai, Zijie Zhuang, and Chong Shang. Real-time multiple people tracking with deeply learned candidate selection and person re-identiﬁcation. In 2018 IEEE

International Conference on Multimedia and Expo (ICME), pages 1–6. IEEE, 2018.
[14] Peng Chu and Haibin Ling. Famnet: Joint learning of feature, afﬁnity and multi-dimensional assignment for online multiple object tracking. In Proceedings of the IEEE International Conference on Computer Vision, pages 6172–6181, 2019.
[15] Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, and Michael Felsberg. ECO: Efﬁcient convolution operators for tracking. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6638–6646, 2017.
[16] Achal Dave, Tarasha Khurana, Pavel Tokmakov, Cordelia Schmid, and Deva Ramanan. TAO: A large-scale benchmark for tracking any object. arXiv preprint arXiv:2005.10356, 2020.
[17] Patrick Dendorfer, Aljosa Osep, Anton Milan, Konrad Schindler, Daniel Cremers, Ian Reid, Stefan Roth, and Laura Leal-Taixe´. MOTChallenge: A benchmark for single-camera multiple target tracking. International Journal of Computer Vision, 2020.
[18] Weitao Feng, Zhihao Hu, Baopu Li, Weihao Gan, Wei Wu, and Wanli Ouyang. SAMOT: Switcher-aware multi-object tracking and still another MOT measure. arXiv preprint arXiv:2009.10338, 2020.
[19] Weitao Feng, Zhihao Hu, Wei Wu, Junjie Yan, and Wanli Ouyang. Multi-object tracking with multiple cues and switcher-aware classiﬁcation. arXiv preprint arXiv:1901.06129, 2019.
[20] Shoudong Han, Piao Huang, Hongwei Wang, En Yu, Donghaisheng Liu, Xiaofeng Pan, and Jun Zhao. MAT: Motion-aware multi-object tracking. arXiv preprint arXiv:2009.04794, 2020.
[21] Joa˜o F Henriques, Rui Caseiro, Pedro Martins, and Jorge Batista. High-speed tracking with kernelized correlation ﬁlters. IEEE Trans. Pattern Anal. Mach. Intell., 37(3):583– 596, 2014.
[22] Roberto Henschel, Laura Leal-Taixe´, Daniel Cremers, and Bodo Rosenhahn. Fusion of head and full-body detectors for multi-object tracking. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 1428–1437, 2018.
[23] Roberto Henschel, Yunzhe Zou, and Bodo Rosenhahn. Multiple people tracking using body and joint detections. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 0–0, 2019.
[24] Andrea Hornakova, Roberto Henschel, Bodo Rosenhahn, and Paul Swoboda. Lifted disjoint paths with application in multiple object tracking. In The 37th International Conference on Machine Learning (ICML), July 2020.
[25] Wei-Chih Hung, Henrik Kretzschmar, Tsung-Yi Lin, Yuning Chai, Ruichi Yu, Ming-Hsuan Yang, and Drago Anguelov. SoDA: Multi-object tracking with soft data association. arXiv preprint arXiv:2008.07725, 2020.
[26] Vicky Kalogeiton, Philippe Weinzaepfel, Vittorio Ferrari, and Cordelia Schmid. Action tubelet detector for spatiotemporal action localization. In Proceedings of the IEEE

International Conference on Computer Vision, pages 4405– 4413, 2017.
[27] Edward K Kao, Matthew P Daggett, and Michael B Hurley. An information theoretic approach for tracker performance evaluation. In 2009 IEEE 12th International Conference on Computer Vision, pages 1523–1529. IEEE, 2009.
[28] Shyamgopal Karthik, Ameya Prabhu, and Vineet Gandhi. Simple unsupervised multi-object tracking. arXiv preprint arXiv:2006.02609, 2020.
[29] Margret Keuper, Siyu Tang, Bjoern Andres, Thomas Brox, and Bernt Schiele. Motion segmentation & multiple object tracking by correlation co-clustering. IEEE Trans. Pattern Anal. Mach. Intell., 42(1):140–153, 2018.
[30] Chanho Kim, Fuxin Li, Arridhana Ciptadi, and James M Rehg. Multiple hypothesis tracking revisited. In Proceedings of the IEEE International Conference on Computer Vision, pages 4696–4704, 2015.
[31] Chanho Kim, Fuxin Li, and James M Rehg. Multi-object tracking with neural gating using bilinear LSTM. In Proceedings of the European Conference on Computer Vision (ECCV), pages 200–215, 2018.
[32] Dahun Kim, Sanghyun Woo, Joon-Young Lee, and In So Kweon. Video panoptic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9859–9868, 2020.
[33] Harold W Kuhn. The Hungarian method for the assignment problem. Naval research logistics quarterly, 2(1-2):83–97, 1955.
[34] Hyemin Lee, Inhan Kim, and Daijin Kim. VAN: Versatile afﬁnity network for end-to-end online multi-object tracking. In Proceedings of the Asian Conference on Computer Vision, 2020.
[35] Seong-Ho Lee, Myung-Yun Kim, and Seung-Hwan Bae. Learning discriminative appearance models for online multiobject tracking with appearance discriminability measures. IEEE Access, 6:67316–67328, 2018.
[36] Ido Leichter and Eyal Krupka. Monotonicity and error type differentiability in performance measures for target detection and tracking in video. IEEE Trans. Pattern Anal. Mach. Intell., 35(10):2553–2560, 2013.
[37] Bo Li, Junjie Yan, Wei Wu, Zheng Zhu, and Xiaolin Hu. High performance visual tracking with siamese region proposal network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8971– 8980, 2018.
[38] Chao Liang, Zhipeng Zhang, Yi Lu, Xue Zhou, Bing Li, Xiyong Ye, and Jianxiao Zou. Rethinking the competition between detection and ReID in multi-object tracking. arXiv preprint arXiv:2010.12138, 2020.
[39] Tsung-Yi Lin, Piotr Dolla´r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2117–2125, 2017.
[40] Qiankun Liu, Qi Chu, Bin Liu, and Nenghai Yu. GSM: graph similarity model for multi-object tracking. In Christian Bessiere, editor, Proceedings of the Twenty-Ninth Inter-

national Joint Conference on Artiﬁcial Intelligence, IJCAI 2020, pages 530–536. ijcai.org, 2020. [41] Qiankun Liu, Bin Liu, Yue Wu, Weihai Li, and Nenghai Yu. Real-time online multi-object tracking in compressed domain. IEEE Access, 7:76489–76499, 2019. [42] Wei Liu, Olga Russakovsky, Jia Deng, Li Fei-Fei, and Alexander C. Berg. ILSVRC 2016: Object detection from video (workshop slides). Online at http://image-net.org/challenges/talks/ 2016/ILSVRC2016_10_09_vid.pdf. [43] Jonathon Luiten, Aljosa Osep, Patrick Dendorfer, Philip Torr, Andreas Geiger, Laura Leal-Taixe´, and Bastian Leibe. HOTA: A higher order metric for evaluating multi-object tracking. International Journal of Computer Vision, 2020. [44] Andrii Maksai and Pascal Fua. Eliminating exposure bias and metric mismatch in multiple object tracking. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4639–4648, 2019. [45] Vasant Manohar, Padmanabhan Soundararajan, Harish Raju, Dmitry Goldgof, Rangachar Kasturi, and John Garofolo. Performance evaluation of object detection and tracking in video. In Asian Conference on Computer Vision, pages 151– 161. Springer, 2006. [46] Anton Milan, Laura Leal-Taixe´, Ian Reid, Stefan Roth, and Konrad Schindler. MOT16: A benchmark for multi-object tracking. arXiv preprint arXiv:1603.00831, 2016. [47] Thuy C Nguyen, Anh H. Vo, Chuong H. Nguyen, , and Yamazaki Masayuki. DSTNet: Unifying detection, segmentation, and tracking via self-supervised and semi-supervised learning. https://github.com/thuyngch/DSTNet, 2020. [48] Bo Pang, Yizhuo Li, Yifan Zhang, Muchen Li, and Cewu Lu. TubeTK: Adopting tubes to track multi-object in a one-step training model. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6308– 6318, 2020. [49] Jiangmiao Pang, Linlu Qiu, Haofeng Chen, Qi Li, Trevor Darrell, and Fisher Yu. Quasi-dense instance similarity learning. arXiv preprint arXiv:2006.06664, 2020. [50] Ioannis Papakis, Abhijit Sarkar, and Anuj Karpatne. Gcnnmatch: Graph convolutional neural networks for multiobject tracking via sinkhorn normalization. arXiv preprint arXiv:2010.00067, 2020. [51] Jinlong Peng, Tao Wang, Weiyao Lin, Jian Wang, John See, Shilei Wen, and Erui Ding. TPM: Multiple object tracking with tracklet-plane matching. Pattern Recognition, page 107480, 2020. [52] William M Rand. Objective criteria for the evaluation of clustering methods. Journal of the American Statistical Association, 66(336):846–850, 1971. [53] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster R-CNN: Towards real-time object detection with region proposal networks. In Advances in Neural Information Processing Systems, pages 91–99, 2015. [54] Ergys Ristani, Francesco Solera, Roger Zou, Rita Cucchiara, and Carlo Tomasi. Performance measures and a data set for multi-target, multi-camera tracking. In European Conference on Computer Vision, pages 17–35. Springer, 2016.

[55] Andrew Rosenberg and Julia Hirschberg. V-measure: A conditional entropy-based external cluster evaluation measure. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 410–420, 2007.
[56] Chaobing Shan, Chunbo Wei, Bing Deng, Jianqiang Huang, Xian-Sheng Hua, Xiaoliang Cheng, and Kewei Liang. Tracklets predicting based adaptive graph tracking, 2020.
[57] Han Shen, Lichao Huang, Chang Huang, and Wei Xu. Tracklet association tracker: An end-to-end learning-based association approach for multi-object tracking. arXiv preprint arXiv:1808.01562, 2018.
[58] Hao Sheng, Jiahui Chen, Yang Zhang, Wei Ke, Zhang Xiong, and Jingyi Yu. Iterative multiple hypothesis tracking with tracklet-level association. IEEE Transactions on Circuits and Systems for Video Technology, 29(12):3660–3672, 2018.
[59] Hao Sheng, Yang Zhang, Jiahui Chen, Zhang Xiong, and Jun Zhang. Heterogeneous association graph fusion for target association in multiple object tracking. IEEE Transactions on Circuits and Systems for Video Technology, 29(11):3269– 3280, 2018.
[60] Kevin Smith, Daniel Gatica-Perez, Jean-Marc Odobez, and Sileye Ba. Evaluating multi-object tracking. In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)-Workshops. IEEE, 2005.
[61] Young-Min Song, Kwangjin Yoon, Young-Chul Yoon, Kin Choong Yow, and Moongu Jeon. Online multi-object tracking with GMPHD ﬁlter and occlusion group management. IEEE Access, 7:165103–165121, 2019.
[62] Rainer Stiefelhagen, Keni Bernardin, Rachel Bowers, John Garofolo, Djamel Mostefa, and Padmanabhan Soundararajan. The CLEAR 2006 evaluation. In International evaluation workshop on classiﬁcation of events, activities and relationships. Springer, 2006.
[63] Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et al. Scalability in perception for autonomous driving: Waymo Open Dataset. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2446–2454, 2020.
[64] ShiJie Sun, Naveed Akhtar, HuanSheng Song, Ajmal Mian, and Mubarak Shah. Deep afﬁnity network for multiple object tracking. IEEE transactions on pattern analysis and machine intelligence, 43(1):104–119, 2019.
[65] Ismail H Toroslu and Go¨ktu¨rk U¨ c¸oluk. Incremental assignment problem. Information Sciences, 177(6):1523–1529, 2007.
[66] Gaoang Wang, Yizhou Wang, Haotian Zhang, Renshu Gu, and Jenq-Neng Hwang. Exploit the connectivity: Multiobject tracking with TrackletNet. In Proceedings of the 27th ACM International Conference on Multimedia, pages 482– 490, 2019.
[67] Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, et al. Deep high-resolution representation learning for visual recognition. IEEE Trans. Pattern Anal. Mach. Intell., 2020.

[68] Yu Wang, Sijia Chen, Li Huang, Runzhou Ge, Yihan Hu, Zhuangzhuang Ding, and Jie Liao. 1st place solutions for Waymo Open Dataset challenges – 2D and 3D tracking. arXiv preprint arXiv:2006.15506, 2020.
[69] Yongxin Wang, Xinshuo Weng, and Kris Kitani. Joint detection and multi-object tracking with graph neural networks. arXiv preprint arXiv:2006.13164, 2020.
[70] Xinshuo Weng, Jianren Wang, David Held, and Kris Kitani. 3D Multi-Object Tracking: A baseline and new evaluation metrics. In International Conference on Intelligent Robots and Systems (IROS), 2020.
[71] Nicolai Wojke, Alex Bewley, and Dietrich Paulus. Simple online and realtime tracking with a deep association metric. In 2017 IEEE International Conference on Image Processing (ICIP), pages 3645–3649, 2017.
[72] Jialian Wu, Jiale Cao, Liangchen Song, Yu Wang, Ming Yang, and Junsong Yuan. Track to detect and segment: An online multi-object tracker. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2021.
[73] Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua Lin. Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3733– 3742, 2018.
[74] Jun Xiang, Guohan Xu, Chao Ma, and Jianhua Hou. Endto-end learning deep CRF models for multi-object tracking. IEEE Transactions on Circuits and Systems for Video Technology, 2020.
[75] Jiarui Xu, Yue Cao, Zheng Zhang, and Han Hu. Spatialtemporal relation networks for multi-object tracking. In Proceedings of the IEEE International Conference on Computer Vision, pages 3988–3998, 2019.
[76] Yihong Xu, Aljosa Osep, Yutong Ban, Radu Horaud, Laura Leal-Taixe´, and Xavier Alameda-Pineda. How to train your deep multi-object tracker. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6787–6796, 2020.
[77] Yuan Xu and Erdene-Ochir Tuguldur. Baseline for 2D object detection and tracking: Cascade R-CNN X152 and SORT. Technical report, Technische Universita¨t Berlin, 2020. Available at https://github.com/ xuyuan/waymo_2d_tracking/blob/f401cd0/ doc/waymo_2d_tracking_dainamite.pdf.
[78] Kwangjin Yoon, Jeonghwan Gwak, Young-Min Song, Young-Chul Yoon, and Moon-Gu Jeon. Oneshotda: Online multi-object tracker with one-shot-learning-based data association. IEEE Access, 8:38060–38072, 2020.
[79] Young-chul Yoon, Abhijeet Boragule, Young-min Song, Kwangjin Yoon, and Moongu Jeon. Online multi-object tracking with historical appearance matching and scene adaptive detection ﬁltering. In 2018 15th IEEE International conference on advanced video and signal based surveillance (AVSS), pages 1–6. IEEE, 2018.
[80] Young-Chul Yoon, Du Yong Kim, Young-min Song, Kwangjin Yoon, and Moongu Jeon. Online multiple pedestrians tracking using deep temporal appearance matching association. Information Sciences, 2020.

[81] Shifeng Zhang, Cheng Chi, Yongqiang Yao, Zhen Lei, and

Stan Z Li. Bridging the gap between anchor-based and

anchor-free detection via adaptive training sample selection.

In Proceedings of the IEEE/CVF Conference on Computer

Vision and Pattern Recognition, pages 9759–9768, 2020.

[82] Yang Zhang, Hao Sheng, Yubin Wu, Shuai Wang, Weifeng

Lyu, Wei Ke, and Zhang Xiong. Long-term tracking with

deep tracklet association. IEEE Trans. Image Process., 2020.

[83] Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng,

and Wenyu Liu. FairMOT: On the fairness of detection and

re-identiﬁcation in multiple object tracking. arXiv preprint

arXiv:2004.01888, 2020.

[84] Xingyi Zhou, Vladlen Koltun, and Philipp Kra¨henbu¨hl.

Tracking objects as points.

arXiv preprint

arXiv:2004.01177, 2020.

[85] Xingyi Zhou, Dequan Wang, and Philipp Kra¨henbu¨hl. Ob-

jects as points. arXiv preprint arXiv:1904.07850, 2019.

[86] Ji Zhu, Hua Yang, Nian Liu, Minyoung Kim, Wenjun Zhang,

and Ming-Hsuan Yang. Online multi-object tracking with

dual matching attention networks. In Proceedings of the Eu-

ropean Conference on Computer Vision (ECCV), pages 366–

382, 2018.

A. Extended results: MOT17
A.1. Comparison of more trackers
Table 2 and Figure 10 gives an extended comparison of the various metrics for the top published trackers. Table 3 and Figure 11 are the same but include unpublished trackers, i.e. submissions for which no publication or technical report is available. A few key observations are as follows.
– DetF1 has a stronger inﬂuence on MOTA, HOTA and IDF1 than on ATA: the trackers with the best DetF1 are typically ranked higher under those metrics.
– Identity switches are a temperamental predictor of the association fraction ATA/DetF1. The methods with the least switches often have a high association fraction but the converse is not necessarily true. For example, ‘GSDT’ (4th in published) and ‘TTS’ (1st in unpublished) have a large number of switches. This may be explained by switch-and-switch-back events.
– Even under ATA, it is possible for improved detection to “compensate” for weaker association. Amongst the unpublished trackers with the highest ATA, 8 of the top 10 algorithms use private detectors. In particular, the trackers ‘HGFMOT’, ‘TLR’ and ‘ReMOT box’ are in the top 10 despite a poor ratio of ATA/DetF1.
Figure 12 shows the decomposition of ATR and ATP error into different types for all published trackers and Figure 13 shows the overall error decomposition of ATA. A few key observations are as follows.
– The top tracker ‘MAT’ stands apart from the next-best published methods.
– As in the main paper, splits have a greater effect than merges, particularly for track precision.
– Trackers using private detectors generally achieve higher track recall and are clustered towards the right of the scatter plot.
– Amongst the trackers which achieve the highest ATA score, ‘LSST17’ has a particularly large fraction of false negative errors, while this quantity is small for ‘GSDT’, ‘Fair’ and ‘CTTrack17’.
– For track precision, the worst methods have a larger fraction of split errors due to unmatched predicted tracks (“best match unavailable”) than due to not ﬁnding the full extent of the ground-truth track (“in partner, not in track”). This suggests that the ground-truth track has been split into many predicted tracks.
Several trackers have two variants submitted to the challenge and it can be informative to contrast these pairs.

‘MAT2’ (using private detections) achieves better ATR than its public counterpart ‘MAT’, but seems to suffer from a much higher rate of split errors. Similarly, ‘CTTrackPub’ is a version of ‘CTTrack17’ (CenterTrack) that is constrained to use the public set of detections for track initialisation. As observed in the main paper, ‘CTTrackPub’ achieves similar precision but signiﬁcantly worse recall. ‘UnsupTrack’, which adds an embedding to CenterTrack, achieves a relative increase in ATP but not ATR, as expected. ‘Tracktor++v2’ achieves a slight boost in both precision and recall over the earlier implementation ‘Tracktor++’. Finally, ‘Lif TsimInt’ is a variant of ‘Lif T’ that uses simple linear interpolation instead of Tracktor-style box regression. This modiﬁcation is shown to have a marginal impact on the metrics.

Table 2. Metric comparison for MOT 2017 benchmark (9 Mar 2021) for top 50 (of 70) published trackers by ATA. The top 5 for each

metric are shown in bold.

Tracker

MOTA

IDSw HOTA0.5 IDF1

DetF1 ALTA(1s) ALTA(5s) ATA ATA/DetF1

MAT [20] Lif TsimInt [24] Lif T [24] * GSDT [69] MPNTrack [8] TT17 [82] * Fair [83] LSST17 [19] * CSTrack [38] * CTTrack17 [84] GSM Tracktor [40] HDTR [1] * FUFET [56] TPM [51] eHAF17 [59] DMAN [86] UnsupTrack [28] * MAT2 [20] STRN MOT17 [75] GNNMatch [50] DEEP TAMA [80] CTTrackPub [84] VAN on [34] SAS MOT17 [44] TLMHT [58] jCC [29] * TraDeS [72] Tracktor++v2 [3] CRF TRA [74] EDMT17 [10] TrctrD17 [76] FWT [22] YOONKJ17 [78] eTC17 [66] NOTA [12] Tracktor++ [3] HAM SADF17 [79] MOTDT17 [13] AM ADM17 [35] MHT DAM [30] AFN17 [57] * Tube TK [48] FAMNet [14] MHT bLSTM [31] LSST17O [19] JBNOT [23] * SST [64] GMPHDOGM17 [61] GMPHD Rd17 [2] OTCD 1 [41]

.671 (7) .582 (15) .605 (13) .662 (9) .588 (14) .549 (20) .737 (3) .547 (21) .749 (2) .678 (6) .564 (17) .541 (23) .762 (1) .542 (22) .518 (32) .482 (50) .617 (11) .695 (4) .509 (38) .573 (16) .503 (42) .615 (12) .552 (19) .442 (64) .506 (41) .512 (37) .691 (5) .563 (18) .531 (26) .500 (43) .537 (24) .513 (35) .514 (34) .519 (31) .513 (36) .535 (25) .483 (49) .509 (39) .481 (51) .507 (40) .515 (33) .630 (10) .520 (30) .475 (53) .527 (27) .526 (28) .524 (29) .499 (44) .468 (55) .486 (48)

1279 (6) 1022 (1) 1189 (4) 3318 (44) 1185 (3) 1088 (2) 3303 (43) 1243 (5) 3567 (47) 3039 (38) 1485 (8) 1895 (15) 3237 (42) 1824 (11) 1834 (12) 2194 (24) 1864 (13) 2844 (37) 2397 (31) 1911 (16) 2192 (23) 2583 (34) 2220 (26) 1529 (9) 1407 (7) 1802 (10) 3555 (46) 1987 (18) 2518 (33) 2264 (27) 1947 (17) 2648 (36) 2118 (21) 2288 (29) 2285 (28) 2072 (20) 1871 (14) 2474 (32) 2214 (25) 2314 (30) 2593 (35) 4137 (52) 3072 (40) 2069 (19) 2167 (22) 3050 (39) 8431 (66) 3125 (41) 3865 (49) 3502 (45)

.677 (4) .626 (10) .638 (9) .662 (5) .603 (12) .601 (13) .719 (2) .589 (15) .721 (1) .651 (7) .565 (19) .566 (18) .700 (3) .518 (35) .535 (28) .532 (30) .582 (17) .649 (8) .537 (26) .557 (20) .520 (34) .595 (14) .537 (25) .535 (29) .547 (24) .535 (27) .652 (6) .550 (23) .527 (31) .509 (40) .527 (32) .479 (48) .454 (55) .555 (21) .526 (33) .518 (36) .500 (44) .511 (39) .505 (43) .480 (47) .478 (49) .586 (16) .000 (68) .506 (42) .554 (22) .508 (41) .489 (45) .000 (68) .518 (37) .477 (50)

.692 (3) .652 (7) .656 (6) .687 (4) .617 (13) .631 (10) .723 (2) .623 (12) .726 (1) .647 (8) .578 (20) .595 (15) .680 (5) .526 (38) .547 (28) .557 (26) .581 (18) .631 (11) .560 (25) .563 (24) .535 (36) .596 (14) .542 (31) .572 (22) .565 (23) .545 (29) .639 (9) .551 (27) .537 (35) .513 (43) .538 (34) .476 (52) .540 (33) .581 (17) .545 (30) .523 (39) .511 (44) .527 (37) .521 (40) .472 (53) .469 (55) .586 (16) .487 (48) .519 (41) .579 (19) .508 (45) .495 (47) .471 (54) .541 (32) .479 (50)

.769 (7) .701 (15) .710 (12) .789 (4) .704 (14) .683 (17) .818 (3) .681 (19) .830 (2) .763 (8) .680 (20) .682 (18) .846 (1) .670 (24) .665 (28) .631 (48) .711 (11) .783 (5) .656 (32) .688 (16) .645 (44) .709 (13) .665 (27) .604 (64) .640 (46) .647 (42) .775 (6) .673 (22) .677 (21) .653 (38) .654 (35) .655 (34) .659 (30) .669 (25) .654 (36) .652 (39) .624 (51) .653 (37) .623 (52) .648 (41) .655 (33) .753 (10) .657 (31) .619 (56) .662 (29) .671 (23) .668 (26) .641 (45) .630 (49) .621 (53)

.660 (1) .587 (8) .585 (9) .612 (5) .596 (6) .571 (13) .623 (4) .565 (14) .627 (3) .583 (10) .548 (18) .559 (16) .630 (2) .544 (19) .538 (20) .506 (33) .576 (11) .591 (7) .507 (31) .562 (15) .513 (27) .552 (17) .522 (23) .485 (44) .518 (25) .506 (32) .574 (12) .525 (22) .519 (24) .509 (28) .509 (29) .505 (34) .517 (26) .507 (30) .499 (36) .503 (35) .490 (42) .497 (38) .479 (47) .492 (40) .497 (39) .529 (21) .487 (43) .479 (46) .479 (45) .497 (37) .454 (49) .471 (48) .424 (54) .454 (50)

.520 (1) .451 (6) .451 (5) .462 (2) .456 (3) .443 (9) .455 (4) .447 (8) .450 (7) .406 (13) .391 (15) .410 (11) .406 (12) .385 (17) .387 (16) .378 (20) .415 (10) .384 (19) .364 (23) .406 (14) .361 (25) .385 (18) .363 (24) .352 (26) .374 (21) .344 (32) .367 (22) .351 (27) .346 (29) .346 (30) .344 (31) .340 (34) .349 (28) .335 (35) .341 (33) .333 (38) .333 (37) .333 (36) .326 (39) .318 (41) .321 (40) .312 (46) .312 (44) .317 (42) .315 (43) .312 (45) .306 (47) .292 (48) .274 (50) .278 (49)

.443 (1) .382 (2) .381 (3) .379 (4) .379 (5) .376 (6) .371 (7) .369 (8) .356 (9) .322 (10) .321 (11) .318 (12) .316 (13) .315 (14) .314 (15) .312 (16) .310 (17) .309 (18) .303 (19) .301 (20) .299 (21) .296 (22) .296 (23) .291 (24) .289 (25) .286 (26) .285 (27) .283 (28) .283 (29) .282 (30) .281 (31) .278 (32) .277 (33) .277 (34) .271 (35) .268 (36) .267 (37) .265 (38) .254 (39) .253 (40) .251 (41) .247 (42) .247 (43) .246 (44) .245 (45) .237 (46) .234 (47) .227 (48) .223 (49) .211 (50)

.577 (1) .545 (3) .537 (6) .481 (9) .538 (5) .550 (2) .453 (16) .543 (4) .429 (24) .422 (27) .472 (11) .466 (13) .373 (42) .471 (12) .472 (10) .495 (7) .435 (21) .395 (38) .462 (15) .437 (20) .464 (14) .418 (30) .445 (18) .483 (8) .452 (17) .441 (19) .368 (44) .420 (29) .417 (31) .432 (22) .430 (23) .424 (26) .420 (28) .414 (33) .415 (32) .412 (34) .429 (25) .406 (36) .407 (35) .390 (39) .383 (40) .328 (50) .376 (41) .398 (37) .370 (43) .354 (46) .350 (48) .354 (47) .354 (45) .339 (49)

Table 3. Metric comparison for MOT 2017 benchmark including unpublished trackers (9 Mar 2021) for the top 50 (of 125) trackers by ATA. The top 5 for each metric are shown in bold.

Tracker

MOTA

IDSw

HOTA0.5 IDF1

DetF1 ALTA(1s) ALTA(5s) ATA ATA/DetF1

* TTS MAT [20] * FBMOT * SeedTrack * hugmot2 * HGFMOT * TLR * XJTU priv * ReMOT box RGCN T LPC MOT * SLA Tracker * FMv2 Lif TsimInt [24] Lif T [24] * SD MOT * GSDT [69] MPNTrack [8] * GIT TT17 [82] hugmot * Fair [83] LSST17 [19] HMM STMA * FMMOT SLA public * CSTrack [38] * CLTSMOT ISDH HDAv2 UNS20regress EMT ALBOD ISE MOT17R * GMTrack FGRNetIV CMT * CTTrack17 [84] GSM Tracktor [40] HDTR [1] * FUFET [56] TPM [51] TrajE SSAT eHAF17 [59] TrajEocc mcmt icv v3 HTracker DMAN [86] * ShallowSORT

.767 (3) .671 (25) .740 (7) .687 (18) .688 (17) .771 (1) .765 (4) .682 (19) .770 (2) .639 (32) .590 (43) .718 (13) .727 (10) .582 (48) .605 (38) .732 (9) .662 (29) .588 (44) .714 (14) .549 (62) .648 (30) .737 (8) .547 (63) .545 (66) .588 (45) .722 (11) .597 (42) .749 (6) .671 (26) .545 (65) .568 (51) .556 (58) .569 (50) .601 (40) .638 (33) .566 (53) .518 (80) .678 (22) .564 (54) .541 (68) .762 (5) .542 (67) .674 (24) .620 (35) .518 (81) .678 (23) .568 (52) .669 (27) .482 (101) .599 (41)

2346 (53) 1279 (9) 2166 (40) 2571 (60) 2190 (42) 3480 (86) 3369 (82) 2262 (48) 2853 (66) 1774 (19) 1122 (3) 2493 (56) 3132 (77) 1022 (1) 1189 (6) 2964 (69) 3318 (81) 1185 (5) 3501 (87) 1088 (2) 2102 (36) 3303 (80) 1243 (8) 1172 (4) 1446 (13) 2199 (45) 1647 (16) 3567 (90) 4983 (109) 3010 (71) 1320 (10) 1361 (11) 2011 (31) 2556 (59) 1893 (26) 1722 (18) 1217 (7) 3039 (72) 1485 (14) 1895 (27) 3237 (79) 1824 (21) 4019 (96) 1850 (23) 1834 (22) 3475 (85) 2055 (33) 4806 (106) 2194 (44) 3045 (73)

.739 (2) .677 (16) .735 (4) .688 (13) .642 (25) .741 (1) .737 (3) .642 (26) .729 (5) .648 (24) .641 (27) .683 (14) .719 (8) .626 (31) .638 (29) .719 (7) .662 (18) .603 (40) .656 (20) .601 (42) .613 (36) .719 (9) .589 (46) .601 (43) .596 (44) .719 (10) .608 (38) .721 (6) .634 (30) .618 (33) .573 (50) .558 (57) .572 (51) .559 (56) .656 (19) .557 (59) .580 (49) .651 (22) .565 (55) .566 (54) .700 (12) .518 (78) .618 (34) .618 (35) .535 (70) .623 (32) .609 (37) .675 (17) .532 (72) .558 (58)

.752 (1) .692 (14) .744 (2) .707 (12) .646 (30) .741 (3) .736 (4) .647 (29) .720 (10) .661 (21) .668 (19) .690 (15) .725 (7) .652 (26) .656 (24) .728 (5) .687 (16) .617 (39) .654 (25) .631 (34) .628 (36) .723 (8) .623 (38) .632 (33) .616 (40) .723 (9) .634 (32) .726 (6) .651 (27) .659 (22) .583 (50) .571 (59) .587 (47) .564 (64) .665 (20) .572 (57) .607 (44) .647 (28) .578 (54) .595 (46) .680 (18) .526 (81) .612 (42) .626 (37) .547 (70) .614 (41) .656 (23) .704 (13) .557 (67) .566 (62)

.849 (2) .769 (26) .818 (8) .815 (9) .788 (19) .845 (4) .844 (5) .782 (21) .853 (1) .746 (33) .708 (44) .801 (14) .807 (12) .701 (47) .710 (42) .811 (10) .789 (18) .704 (45) .809 (11) .683 (53) .753 (31) .818 (7) .681 (56) .680 (57) .700 (48) .801 (13) .717 (39) .830 (6) .794 (15) .698 (50) .681 (55) .667 (73) .721 (37) .729 (36) .720 (38) .679 (59) .657 (80) .763 (29) .680 (58) .682 (54) .846 (3) .670 (68) .763 (28) .713 (40) .665 (75) .767 (27) .690 (51) .790 (17) .631 (100) .738 (35)

.671 (1) .660 (6) .666 (3) .668 (2) .650 (9) .653 (7) .653 (8) .639 (10) .664 (4) .613 (18) .592 (24) .633 (11) .625 (14) .587 (26) .585 (29) .625 (15) .612 (19) .596 (23) .663 (5) .571 (38) .603 (20) .623 (16) .565 (42) .566 (40) .578 (33) .615 (17) .586 (28) .627 (13) .601 (21) .555 (49) .562 (43) .539 (55) .576 (36) .579 (32) .566 (41) .544 (53) .542 (54) .583 (30) .548 (51) .559 (47) .630 (12) .544 (52) .579 (31) .560 (45) .538 (56) .586 (27) .521 (62) .576 (35) .506 (75) .569 (39)

.532 (1) .520 (2) .516 (3) .497 (4) .483 (6) .480 (7) .474 (9) .472 (10) .463 (13) .468 (11) .449 (21) .477 (8) .465 (12) .451 (19) .451 (18) .463 (14) .462 (15) .456 (16) .489 (5) .443 (24) .445 (23) .455 (17) .447 (22) .436 (27) .431 (29) .438 (26) .440 (25) .450 (20) .435 (28) .411 (32) .410 (35) .406 (40) .407 (37) .400 (46) .404 (42) .395 (47) .411 (31) .406 (39) .391 (49) .410 (34) .406 (38) .385 (51) .401 (45) .392 (48) .387 (50) .404 (44) .377 (57) .411 (33) .378 (56) .404 (43)

.465 (1) .443 (2) .427 (3) .422 (4) .398 (5) .391 (6) .389 (7) .389 (8) .387 (9) .386 (10) .385 (11) .384 (12) .383 (13) .382 (14) .381 (15) .380 (16) .379 (17) .379 (18) .378 (19) .376 (20) .372 (21) .371 (22) .369 (23) .366 (24) .361 (25) .360 (26) .360 (27) .356 (28) .350 (29) .348 (30) .341 (31) .333 (32) .328 (33) .326 (34) .325 (35) .324 (36) .324 (37) .322 (38) .321 (39) .318 (40) .316 (41) .315 (42) .314 (43) .314 (44) .314 (45) .314 (46) .313 (47) .313 (48) .312 (49) .310 (50)

.548 (3) .577 (1) .522 (10) .518 (11) .506 (14) .463 (35) .460 (37) .497 (19) .454 (41) .518 (12) .543 (5) .480 (25) .474 (27) .545 (4) .537 (9) .468 (31) .481 (24) .538 (8) .468 (32) .550 (2) .493 (22) .453 (42) .543 (6) .539 (7) .516 (13) .450 (45) .502 (15) .429 (56) .440 (50) .498 (18) .501 (16) .499 (17) .456 (39) .447 (46) .451 (44) .478 (26) .494 (21) .422 (59) .472 (29) .466 (33) .373 (86) .471 (30) .412 (68) .441 (49) .472 (28) .409 (70) .454 (40) .397 (75) .495 (20) .420 (61)

ALTA(x) Relative ALTA(x)

ALTA - MOT17 test
0.8 0.6 0.4 0.2

1.00

0.95

MAT

Lif_TsimInt Lif_T

0.90

* GSDT

MPNTrack

0.85

* Fair

* CSTrack * FUFET

0.80

* MAT2

0.75

ALTA - MOT17 test

MAT Lif_TsimInt Lif_T * GSDT MPNTrack * Fair * CSTrack * FUFET * MAT2

0.0

1

10

100

1000

Horizon (frames)

0.70 1

10

100

1000

Horizon (frames)

Figure 10. The published trackers which achieve the highest ALTA at any horizon (top 5 highlighted). Other trackers are shown in grey. The right ﬁgure shows the value relative to the best tracker at each horizon for easier comparison.

ALTA(x) Relative ALTA(x)

0.8

0.6

0.4

0.2

0.0

1

ALTA - MOT17 test

10

100

1000

Horizon (frames)

* TTS MAT * FBMOT * SeedTrack * hugmot2 * HGFMOT * TLR * ReMOT_box * GIT * FUFET

1.00 0.95 0.90 0.85 0.80 0.75 0.70
1

ALTA - MOT17 test

10

100

1000

Horizon (frames)

* TTS MAT * FBMOT * SeedTrack * hugmot2 * HGFMOT * TLR * ReMOT_box * GIT * FUFET

Figure 11. The trackers (published or unpublished) which achieve the highest ALTA at any horizon (top 5 highlighted). Other trackers are shown in grey. The right ﬁgure shows the value relative to the best tracker at each horizon for easier comparison.

1.0

0.8

Track Prec

0.6

0.4

0.2

GTGSGPH*rMGG*GTSGSAaHHMPMDTCUIACMRcMrLAPMGMDYMCEHTM*HniSPTP*EkMPMaMfSP_NP_DML_HrPsTHET*NTtPCODPTIH____cHETG*rDTHPHSS_ASaeHOT_HuPCMGrFoLOH*VDN*RrSkTOOHTAurJaDITTEr_ADDcMcSbMSTATpSMN_ASDFtTAHeSDODDrFAsaPD_D_tc__abL*MNkBTiGDD_*LHA_TFGN_OTTT_FM_o+TRODSMO_OaT_rMDADcCDURALkcNM_eFrrraDerKDPNGSTiALMS1NjPSMTDFTUNFTFMTdTAkLTTTTMLSFJOMDFKCMTtA_mr_fkDDP+DaaaNtIP1TCGA7HASNCT+HR11111111111cS1111111OED_WHSTaTM1M1_T1oAACTve11uVcccieoTn777TC7TNh7TTRT7NOT7MT7777SM7M7DM7A77TP7LN7MA7F71A27TntrAkKkSk2+rtr7b71

0.0

Precision error (predicted tracks) FP det Merge (contains multiple) Split (best match unavailable) Split (in partner, not in track) FN det (in partner, not in track) 0.4

0.3

0.2

0.1

0.0 0.1

0.2

0.3

0.4

Rec0FSMMFa.NPp5leellrrdidetggereee(rttco(((oribinnn(etgppsartaaionrrmusttnnnamdeetcrr-ut,,hlrtnnuiupootnhltteaiit)nnvraatticrrlaaakccbskk)le)))GTGGHSMPG*GrGGMTHHSMSA*DaPUCMTACMMRMMAMGIcDLPHCHEYrTMnSPM*TMPEMN*kDPSiHaPPHN__PELOTD_TCTfsPH*rHGPTDHtETH_Mc_H_O_THGAPSOC*SISHaeDPuTrV_NF_oROLOHSrD*ATMMD*kuDTMAarTTENDAbDSSOcDDH_ATrpSSTcATDrSeAJF_IDMFaPstDNDGrba_BHc_MOGLT__NA+MkM*OOLtTODD_RDTDTT*F_FCUo_MATAS_RaT_Nic__DDLMrkGNecMaFKAe_mMNPMSSMTDM1LNSDOUrrrPTArd+TCTTKTTTSFTDTDDkAFFLLFTFi_PkjNG_WaaaCtArH+1JNTMMfPHA7OCSDHRT1111111t111111111S11ASEC1TAa1To1cITVT_1e1u_vccceoTnMMMMMODNNNCAR+A7777777777777777hSTA77PTTTTTTAiT1n77L27FTK2S77b1kkkrtrrt0.0

0.2

0.4

0.6

0.8

1.0

Track Recall

Figure 12. Decomposition of track precision (ATP) and recall (ATR) for the 70 published trackers on the MOT 2017 benchmark. Trackers that use a private detector are distinguished by a ﬁlled marker.

1.0

MOT17 test

0.8

0.6

0.4

0.2

0.0

Det false neg Det false pos Assoc split Assoc merge Correct (approx)

ATA GTGSGPH*rMGG*GTSGSAaHHMPMDTCUIACMRcMrLAPMGMDYMCEHTM*HniSPTP*EkMPMaMfSP_NP_DML_HrPsTHET*NTtPCODPTIH____cHETG*rDTHPHSS_ASaeHOT_HuPCMGrFoLOH*VDN*RrSkTOOHTAurJaDITTEr_ADDcMcSbMSTATpSMN_ASDFtTAHeSDODDrFAsaPD_D_tc__abL*MNkBTiGDD_*LHA_TFGN_OTTT_FM_o+TRODSMO_OaT_rMDADcCDURALkcNM_eFrrraDerKDPNGSTiALMS1NjPSMTDFTUNFTFTMdTAkLTTTTMLSFJOMDFKCMTtA_mr_fkDDP+DaaaNtIP1TCGA7HASNCT+HR11111111111cS1111111OE_DWHSTaTM1M1_T1oAACTve11uVcccieoTn777TCT7NT7hTR7TNOT7MT7777SM7M7DM7A77TP7LN7MA7F71A27TntrAkKkSk2+rtr7b71

Figure 13. Distribution of error types in ATA for the 70 published trackers in the MOT 2017 benchmark.

A.2. Temporal error decomposition
The time-varying error decomposition for the 11 selected trackers are shown below. Split errors generally occur at shorter temporal horizons than merge errors and in much greater proportion. For several trackers, the fraction of false-positive detection errors increases with the fraction of split errors. While it may seem counter-intuitive for the fraction of detection errors to depend on the temporal horizon, it is a natural effect of there being more predicted tracks than ground-truth tracks.

1.0

MOT17 test - CTTrack17

1.0

MOT17 test - CTTrackPub

1.0

MOT17 test - DMAN

0.8

0.8

0.8

0.6

0.6

0.6

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

1.0

MOT17 test - Fair

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

1.0

MOT17 test - Lif_T

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

1.0

MOT17 test - LSST17

0.8

0.8

0.8

0.6

0.6

0.6

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

1.0

MOT17 test - LSST17O

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

1.0

MOT17 test - MAT

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

1.0

MOT17 test - MPNTrack

0.8

0.8

0.8

0.6

0.6

0.6

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

1.0

MOT17 test - Tracktor++v2

1.0

MOT17 test - Tube_TK

0.8

0.8

0.6

0.6

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

0.4

Error: det, false neg

Error: det, false pos

Error: assoc, split

0.2

Error: assoc, merge

ALTA (approx)

ALTA

0.0 100

101

102

103

Horizon (frames)

Figure 14. Time-varying error decomposition of ALTA for selected trackers.

A.3. Per-sequence temporal analysis
The per-sequence results for the 11 selected trackers are shown below. The 3 columns correspond to the 3 different sets of public detections (DPM, FRCNN, SDP). The methods which use their own, external detector have the same results for each set of detections. Note that ALTA is not necessarily monotonically decreasing. It may occur that a tracker achieves a higher ALTA score at a longer horizon if it is able to recover from incorrect associations.

ALTA(x)

ALTA - Temporal behaviour - MOT17 test
0.9

ALTA(x)

0.8

MAT

0.7

Lif_T MPNTrack

* Fair

0.6

LSST17

* CTTrack17

0.5

DMAN CTTrackPub

Tracktor++v2

0.4

* Tube_TK

LSST17O

0.3

0.2 1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-01-DPM

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA(x)

ALTA - MOT17 test - MOT17-01-FRCNN

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-03-DPM

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA(x)

ALTA - MOT17 test - MOT17-03-FRCNN

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-06-DPM

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA(x)

ALTA - MOT17 test - MOT17-06-FRCNN

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA(x)

ALTA(x)

ALTA(x)

ALTA - MOT17 test - MOT17-01-SDP

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-03-SDP

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-06-SDP

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA(x)

ALTA(x)

ALTA(x)

ALTA(x)

ALTA - MOT17 test - MOT17-07-DPM

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-08-DPM

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-12-DPM

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-14-DPM
0.9

0.8 0.7

0.6 0.5

0.4 0.3

0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA(x)

ALTA(x)

ALTA(x)

ALTA(x)

ALTA - MOT17 test - MOT17-07-FRCNN

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-08-FRCNN

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-12-FRCNN

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-14-FRCNN
0.9

0.8 0.7

0.6 0.5

0.4 0.3

0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA(x)

ALTA(x)

ALTA(x)

ALTA(x)

ALTA - MOT17 test - MOT17-07-SDP

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-08-SDP

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-12-SDP

0.9 0.8

0.7 0.6

0.5 0.4

0.3 0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA - MOT17 test - MOT17-14-SDP
0.9

0.8 0.7

0.6 0.5

0.4 0.3

0.2

0.1

1

10

100

1000

Horizon (frames)

ALTA(x)

ALTA(x)

Figure 15. ALTA versus horizon for each of the 21 sequences in the MOT 2017 test set.

B. Extended results: Waymo Open Dataset
B.1. Tracker descriptions
We brieﬂy describe the trackers which were evaluated on the Waymo Open Dataset 2D tracking benchmark. Of the nine trackers, two were submitted by the original authors of a formal paper (Quasi-Dense R101 [49] and Online V-IOU [6]), three more were accompanied by a technical report (HorizonMOT [68], CascadeRCNN-SORT v2 [77], and DSTNet [47]) and the remaining four provided only a short description. For these four trackers (denoted by †), we cite the algorithm from the description with the caveat that the submission was not made by its original authors.
Quasi-Dense R101 [49] is a joint detection and embedding approach that associates detections over time without taking into account location or motion. Association is performed by bidirectional matching and low-scoring region proposals (“backdrops”) are retained during training and testing to make the method “quasi-dense”. The detector is a Feature Pyramid Network [39] Faster R-CNN [53] and the embedding is trained with the non-parametric softmax loss [73]. Unmatched tracks are kept alive for up to ten frames. Online V-IOU is an online version of the Visual IOU tracker [7], which enhances a simplistic IOU tracker by employing a single-object tracker (KCF [21]) to extend tracks that would otherwise have been terminated. Detections are obtained using Cascade R-CNN [9] with a HRNetV2 backbone [67]. HorizonMOT [68] (no relation to our temporal horizon) is a tracking-by-detection framework that uses CenterNet [85] for detections and includes a deep re-ID framework based on [71] to match object appearances via the cosine distance. A fallback matching mechanism based on IOU is used for detections that could not be matched by appearance. CascadeRCNN-SORT v2 [77] combines a Cascade R-CNN detector [9] with SORT-based tracking [5] a grid search was performed to ﬁnd optimal SORT parameters for each class independently. The submission named simply Sort† uses the same detection architecture and tracking algorithm. However, the different characteristics in both our analysis and the ofﬁcial MOTA ranking indicate that different hyper-parameters must have been used. Yet another submission based on SORT is dereyly alex†, which obtains detections using an ensemble of two detectors from the MMDetection toolbox [11]. The ﬁnal three trackers were submitted by the same set of authors. FCTrack† uses FairMOT [83], which is a joint detection and re-ID network based on CenterNet with a DLA-34 backbone [85], DSTNet [47] is described as a uniﬁed Detection-Segmentation-Tracking approach with a softmax-based cross entropy loss for learning track embeddings, while ATSS-Track† is simply stated to use Adaptive Training Sample Selection [81] to train its detector with no additional information.

B.2. Detailed results
The main paper presented the ALTA plot for the vehicle class only. This section presents further results for the pedestrian and cyclist classes, as well as for all classes combined. While the paper did not consider the problem of how to combine metrics for multiple classes, for these experiments we follow the Waymo Open Dataset in simply combining the different classes as different sequences. For each tracker, we selected a per-class score threshold for the detections to maximise the detection F1-score (the ofﬁcial evaluation server tries several thresholds and adopts that which maximises MOTA).
Figure 16 shows the temporal characterisation of ALTA for the pedestrian and cyclist classes. Figure 17 compares ALTA and LIDF1 for all classes. Figure 18 shows the decompositions of track precision and recall for each individual class and all classes combined. Tables 4, 5, 6 and 7 present the full metrics for completeness, including a comparison to MOTA and IDF1. A few key observations are as follows.
– As before, ATA is less correlated with detection and more correlated with identity switches compared to MOTA and IDF1.
– All methods are signiﬁcantly worse for cyclist than for other classes, both in terms of ATR and ATP, and this is mostly due to detection errors.
– Trackers that do not use an appearance embedding and focus on association using motion, such as ‘Online VIOU’ and the three trackers based on SORT, have their track precision severely impacted by split errors.
– The trackers which are most impacted by merge errors are the joint detection-and-embedding network ‘FCTrack’ and the two other trackers from the same team, ‘DSTNet’ and ‘ATSS-Track’. These achieve the best precision and the worst recall.
– ‘Quasi-Dense R101’, which also uses instance embeddings, achieves higher recall by reducing both falsenegative detections and merge errors.
It is particularly interesting that ‘Quasi-Dense R101’ achieves the best ATA without making use of spatial location or velocity. This is the reverse of the MOT17 challenge, where the highest-ranking tracker, MAT, used only spatial information to perform association. This may be due to the relatively low frame-rate and large camera motion in the Waymo dataset, although it is difﬁcult to draw a conclusion without evaluating both methods on the same dataset.

ALTA(x)

0.8 ALTA - Waymo test (pedestrian)

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0.0

1

10

100

Horizon (frames)

ALTA - Waymo test (cyclist)

0.6

Quasi-Dense R101 HorizonMOT

0.5

FCTrack DSTNet

0.4

ALTA(x)

ATSS-Track

Sort

0.3

dereyly_alex

Online V-IOU

0.2

CascadeRCNN-SORT v2

0.1

0.0

1

10

100

Horizon (frames)

Quasi-Dense R101 CascadeRCNN-SORT v2 HorizonMOT DSTNet ATSS-Track Online V-IOU FCTrack Sort dereyly_alex

Figure 16. ALTA versus horizon for pedestrians and cyclists on the Waymo Open Dataset.

ALTA(x)

ALTA - Waymo test (all classes)
0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0.0

1

10

100

Horizon (frames)

Quasi-Dense R101 HorizonMOT FCTrack DSTNet ATSS-Track dereyly_alex Sort CascadeRCNN-SORT v2 Online V-IOU

Relative ALTA(x)

ALTA - Waymo test (all classes)
1.0

0.9

0.8

0.7

0.6

0.5

1

10

100

Horizon (frames)

Quasi-Dense R101 HorizonMOT FCTrack DSTNet ATSS-Track dereyly_alex Sort CascadeRCNN-SORT v2 Online V-IOU

LIDF1(x)

LIDF1 - Waymo test (all classes)
0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0.0

1

10

100

Horizon (frames)

Quasi-Dense R101 HorizonMOT CascadeRCNN-SORT v2 dereyly_alex Sort Online V-IOU DSTNet ATSS-Track FCTrack

Relative LIDF1(x)

LIDF1 - Waymo test (all classes)
1.00

0.95

0.90

0.85

0.80

0.75

1

10

100

Horizon (frames)

Quasi-Dense R101 HorizonMOT CascadeRCNN-SORT v2 dereyly_alex Sort Online V-IOU DSTNet ATSS-Track FCTrack

Figure 17. Comparison of ALTA (top) and LIDF1 (bottom) as a function of horizon for all classes in the Waymo benchmark. The two metrics coincide in a detection metric at zero horizon and association has a much greater inﬂuence on ALTA than LIDF1. The plots on the right show the metric relative to the best tracker at each horizon for easier comparison.

Waymo test (vehicle)
1.0

Waymo test (pedestrian)
1.0

0.8

0.8

Track Prec

Track Prec

0.6

0.6

0.4

0.4

0.2

0.2

0.0

CascaQdueasRid-CeOAHDNrnToeleNirS-niyFnlSsSzC-yeDeoO_TTSnrrVRaRS-TlaaITM1oecNcrO0Oxvktke1TtU2

PrecFMSSFiPNppseillrodiidttgneee((ttbien(e(rcirpsnootanrprmtt(aanpariertntencrs,dehmnircu,otunnetlaotdiinvtptailtrneiral)aactcbrkaklsec)))kC)ascQadueaRsdiC-OeHDNrnoeNelrniy-niSszleyeOo_nVRaRSM-Tl1oIeOO0rxvtU1T2

Recall error (ground-truth tracks) FN det Split (contains multiple) Merge (best match unavailable) Merge (in partner, not in track)

ATSFSCD-TTSrrTaaNcckekt

FP det (in partner, not in track)

0.0 0.2 0.4 0.6 0.8 1.0

Track Recall

Waymo test (cyclist)
1.0

CascadeRdCeONrnleNi-ynlSyeO_VRa-lITeOxvU2 Quasi-AHDToerSniFSszC-DeoTTSnrrRSTaaM1ocNcr0Oktke1Tt

0.0

PrecFMSSFRiPNppseeillcrodiidFSttganeeNpe((ltltbilenide(et(rcirerpsn(orotctaonrpormrtt(ana(npartgiertantrencrison,dehumsnircnu,omtudnnetl-aoutditinvtlrpttuaiiltrnpetiralhl)aaectcbrkt)akrlseac)))ckCk)ass)cQadueaRsdiC-OeHDNrnoeNelrniy-FniSszlCDeyeOoT_SnVRraRSTMa-Tl1oINecOO0rxvketU1T2t

Merge (best match unavailable) Merge (in partner, not in track) FP det (in partner, not in track)

ATSS-Track 0.0

0.2

0.4

0.6

0.8

1.0

Track Recall

Waymo test (all classes)
1.0

0.8

0.8

Track Prec

Track Prec

0.6

0.6

0.4

0.4

0.2

0.2

deOHrnoleiriyFnlzCyeDo_TSnrVa-TlaIMecNOOxkeTtU CascaQdueasRi-CADNTeNS-nSsS-eOTrRRSaT1ocr0vtk12

0.0

0.0

CascadeRCONnlNi-nSeOVR-ITOvU2 Quasid-eAHDrToeerSniyFlSszC-yDeo_TTSnrraRSTlaaM1oecNcr0Oxktke1Tt

PrecFMSSFRiPNppseeillcrodiidFSMMttganeeNpe((leetltbilenrride(et(ggrcirerpsnee(orotctaonrp((ormrbitt(anna(npeartgieprstantrenctraison,dehrmumsntircnun,aomtudnentetlcr-aoutdit,hinvtlrptntuaiiultrnpoetiranlhlt)aaectacbrikt)nvakrlsaeac))ti)ckrlCaak)acbssk)lce)Qa)dueaRsdiC-OeAHDNrnToeNelSrniy-FniSSszlCDeye-OoTT_SnVRraRrSTMaa-Tl1oINeccOO0rxvkektU1T2t

FP det (in partner, not in track)

0.0 0.2 0.4 0.6 0.8 1.0

Track Recall

PrecFMSSFiPNppseillrodiidttgneee((ttbien(e(rcirpsnootanrprmtt(aanpariertntencrs,dehmnircu,otunnetlaotdiinvtptailtrneiral)aactcbrkaklsec)))kC)ascQadueaRsdiC-OeHDNrnoeNelrniy-niSszleyeOo_nVRaRSM-Tl1oIeOO0rxvtU1T2

Recall error (ground-truth tracks) FN det Split (contains multiple) Merge (best match unavailable) Merge (in partner, not in track) FP det (in partner, not in track)

ATSFSCD-TTSrrTaaNcckekt0.0

0.2

0.4

0.6

0.8

1.0

Track Recall

Figure 18. Decomposition of tracker error types for each class in the Waymo Open Dataset.

Table 4. Metric comparison for vehicle class on the Waymo 2D tracking benchmark.

Submission

MOTA IDF1 DetF1 ALTA(1s) ALTA(5s) ATA ATA/DetF1

Quasi-Dense R101 [49]
CascadeRCNN-SORT v2 [77] dereyly alex† [5]
HorizonMOT [68] FCTrack† [83]
DSTNet [47] Sort† [5] ATSS-Track† [81]
Online V-IOU [7]

.492 (1) .474 (3) .413 (5) .472 (4) .373 (8) .410 (6) .372 (9) .385 (7) .480 (2)

.713 (1) .615 (4) .622 (3) .629 (2) .527 (9) .565 (7) .596 (5) .557 (8) .571 (6)

.802 (1) .727 (5) .717 (6) .796 (2) .690 (9) .738 (4) .708 (8) .716 (7) .767 (3)

.646 (1) .533 (4) .521 (5) .521 (6) .514 (7) .567 (2) .510 (8) .536 (3) .475 (9)

.530 (1) .404 (4) .397 (5) .393 (6) .389 (7) .426 (2) .369 (8) .404 (3) .309 (9)

.481 (1) .356 (2) .351 (3) .350 (4) .330 (5) .324 (6) .318 (7) .317 (8) .257 (9)

.600 (1) .490 (2) .490 (3) .440 (7) .479 (4) .439 (8) .450 (5) .443 (6) .336 (9)

Table 5. Metric comparison for pedestrian class on the Waymo 2D tracking benchmark.

Submission

MOTA IDF1 DetF1 ALTA(1s) ALTA(5s) ATA ATA/DetF1

Quasi-Dense R101 [49]
HorizonMOT [68] FCTrack† [83]
DSTNet [47] ATSS-Track† [81] Sort† [5] dereyly alex† [5]
Online V-IOU [7]
CascadeRCNN-SORT v2 [77]

.529 (1) .517 (2) .396 (7) .456 (5) .411 (6) .357 (9) .371 (8) .459 (4) .485 (3)

.628 (1) .598 (2) .465 (6) .471 (4) .436 (8) .433 (9) .467 (5) .461 (7) .527 (3)

.744 (3) .749 (2) .650 (6) .683 (5) .642 (7) .557 (9) .604 (8) .707 (4) .753 (1)

.566 (1) .507 (2) .441 (5) .491 (3) .449 (4) .369 (8) .374 (6) .370 (7) .333 (9)

.458 (1) .400 (2) .341 (4) .368 (3) .337 (5) .245 (6) .242 (7) .225 (8) .183 (9)

.417 (1) .361 (2) .303 (3) .287 (4) .267 (5) .203 (6) .200 (7) .187 (8) .145 (9)

.561 (1) .483 (2) .466 (3) .421 (4) .416 (5) .365 (6) .331 (7) .265 (8) .193 (9)

Table 6. Metric comparison for cyclist class on the Waymo 2D tracking benchmark.

Submission

MOTA IDF1 DetF1 ALTA(1s) ALTA(5s) ATA ATA/DetF1

Quasi-Dense R101 [49]
CascadeRCNN-SORT v2 [77]
HorizonMOT [68]
DSTNet [47] ATSS-Track† [81]
Online V-IOU [7] FCTrack† [83] Sort† [5] dereyly alex† [5]

.332 (3) .365 (1) .365 (2) .274 (4) .272 (5) .264 (6) .182 (9) .230 (7) .227 (8)

.501 (2) .481 (3) .507 (1) .450 (5) .448 (6) .385 (7) .351 (9) .351 (8) .451 (4)

.552 (3) .584 (2) .620 (1) .516 (5) .501 (6) .487 (7) .404 (8) .404 (9) .530 (4)

.425 (1) .418 (2) .393 (3) .337 (4) .332 (6) .334 (5) .254 (9) .290 (8) .299 (7)

.357 (1) .317 (2) .289 (3) .266 (5) .266 (4) .252 (6) .209 (8) .216 (7) .181 (9)

.315 (1) .273 (2) .241 (3) .237 (4) .237 (5) .216 (6) .190 (7) .180 (8) .136 (9)

.570 (1) .467 (4) .389 (8) .460 (5) .473 (2) .444 (7) .469 (3) .445 (6) .257 (9)

Table 7. Combined results for all classes on the Waymo 2D tracking benchmark.

Submission

MOTA IDF1 DetF1 ALTA(1s) ALTA(5s) ATA

Quasi-Dense R101 [49]
HorizonMOT [68] FCTrack† [83]
DSTNet [47] ATSS-Track† [81] dereyly alex† [5] Sort† [5]
CascadeRCNN-SORT v2 [77]
Online V-IOU [7]

.451 (2) .451 (1) .317 (9) .380 (5) .356 (6) .337 (7) .320 (8) .442 (3) .401 (4)

.688 (1) .619 (2) .509 (9) .538 (7) .523 (8) .578 (4) .552 (5) .586 (3) .540 (6)

.784 (1) .781 (2) .676 (8) .721 (5) .694 (6) .684 (7) .667 (9) .734 (4) .748 (3)

.620 (1) .515 (3) .489 (5) .541 (2) .508 (4) .474 (6) .469 (7) .448 (8) .441 (9)

.505 (1) .394 (3) .371 (5) .406 (2) .382 (4) .345 (6) .332 (7) .293 (8) .280 (9)

.458 (1) .352 (2) .319 (3) .311 (4) .301 (5) .298 (6) .284 (7) .245 (8) .233 (9)

ATA/DetF1
.584 (1) .451 (3) .472 (2) .431 (6) .433 (5) .436 (4) .426 (7) .334 (8) .311 (9)

